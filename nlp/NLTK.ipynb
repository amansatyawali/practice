{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d0b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/aman.satyawali/anaconda3/lib/python3.7/site-packages (3.6.1)\n",
      "Requirement already satisfied: regex in /home/aman.satyawali/anaconda3/lib/python3.7/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in /home/aman.satyawali/anaconda3/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /home/aman.satyawali/anaconda3/lib/python3.7/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in /home/aman.satyawali/anaconda3/lib/python3.7/site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "#install the NLTK library\n",
    "\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad81ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd41acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'data = \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\" '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c77069e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/aman.satyawali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # downloading a model specifically made for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e254c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence tokenization\n",
    "\n",
    "sentences = nltk.sent_tokenize(data)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca8e9867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(data)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47815411",
   "metadata": {},
   "source": [
    "# POS (part of speech tagging)\n",
    "\n",
    "9 POS are there : \n",
    "- nouns\n",
    "- pronouns\n",
    "- verbs\n",
    "- adverbs\n",
    "- adjectives\n",
    "- articles\n",
    "- prepositions\n",
    "- conjunctions\n",
    "- interjections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de58a8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/aman.satyawali/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading a model specifically made for pos tagging\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f2cde4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('!', '.'),\n",
       " ('see', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('example', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('POS', 'NNP'),\n",
       " ('tagging', 'VBG')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'We will! see an example of POS tagging'\n",
    "\n",
    "# word tokens are tagged\n",
    "\n",
    "words = nltk.word_tokenize(data)\n",
    "pos = nltk.pos_tag(words)\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9218a7",
   "metadata": {},
   "source": [
    "https://www.guru99.com/pos-tagging-chunking-nltk.html\n",
    "\n",
    "\n",
    "Abbreviation \tMeaning\n",
    "- CC   -> coordinating conjunction\n",
    "- CD   -> cardinal digit\n",
    "- DT   -> determiner\n",
    "- EX   -> existential there\n",
    "- FW   -> foreign word\n",
    "- IN   -> preposition/subordinating conjunction\n",
    "- JJ   -> This NLTK POS Tag is an adjective (large)\n",
    "- JJR  -> adjective, comparative (larger)\n",
    "- JJS  -> adjective, superlative (largest)\n",
    "- LS   -> list market\n",
    "- MD   -> modal (could, will)\n",
    "- NN   -> noun, singular (cat, tree)\n",
    "- NNS  -> noun plural (desks)\n",
    "- NNP  -> proper noun, singular (sarah)\n",
    "- NNPS -> proper noun, plural (indians or americans)\n",
    "- PDT  -> predeterminer (all, both, half)\n",
    "- POS  -> possessive ending (parent\\ ‘s)\n",
    "- PRP  -> personal pronoun (hers, herself, him,himself)\n",
    "- PRP  -> possessive pronoun (her, his, mine, my, our )\n",
    "- RB   -> adverb (occasionally, swiftly)\n",
    "- RBR  -> adverb, comparative (greater)\n",
    "- RBS  -> adverb, superlative (biggest)\n",
    "- RP   -> particle (about)\n",
    "- TO   -> infinite marker (to)\n",
    "- UH   -> interjection (goodbye)\n",
    "- VB   -> verb (ask)\n",
    "- VBG  -> verb gerund (judging)\n",
    "- VBD  -> verb past tense (pleaded)\n",
    "- VBN  -> verb past participle (reunified)\n",
    "- VBP  -> verb, present tense not 3rd person singular(wrap)\n",
    "- VBZ  -> verb, present tense with 3rd person singular (bases)\n",
    "- WDT  -> wh-determiner    (that, what)\n",
    "- WP   -> wh- pronoun    (who)\n",
    "- WRB  -> wh- adverb     (how)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44883c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aman\n",
      "left\n"
     ]
    }
   ],
   "source": [
    "# Removing punctuations\n",
    "\n",
    "import string\n",
    "punct = string.punctuation\n",
    "\n",
    "eg = ['aman', '!', 'left']\n",
    "\n",
    "for i in eg :\n",
    "    if i not in punct :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e5d21ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aman.satyawali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ac90534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59645cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_remove_punctuation(data) : \n",
    "    result = []\n",
    "    data = data.lower()\n",
    "    data = nltk.word_tokenize(data)\n",
    "    punct = string.punctuation\n",
    "    stop_words = stopwords.words('english')\n",
    "    for word in data :\n",
    "        if word not in punct and word not in stop_words :\n",
    "            result.append(i)\n",
    "            \n",
    "    return nltk.pos_tag(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd22c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('left', 'NN'), ('left', 'VBD'), ('left', 'JJ'), ('left', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "data = 'We will! see An example of POS tagging'\n",
    "clean_data = tokenize_and_remove_punctuation(data)\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71a7d3",
   "metadata": {},
   "source": [
    "<h2>Stemming and Lemmatization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee23d3",
   "metadata": {},
   "source": [
    "<h3>Stemming</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ff64055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1223ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "best\n",
      "<--------------------------------------------------------->\n",
      "Snowball stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "best\n",
      "<--------------------------------------------------------->\n",
      "Lancaster stemmer\n",
      "hobby\n",
      "hobby\n",
      "comput\n",
      "comput\n",
      "best\n"
     ]
    }
   ],
   "source": [
    "print('Porter stemmer')\n",
    "print(porter.stem('hobby'))\n",
    "print(porter.stem('hobbies'))\n",
    "print(porter.stem('computer'))\n",
    "print(porter.stem('computation'))\n",
    "print(porter.stem('best'))\n",
    "print('<--------------------------------------------------------->')\n",
    "print('Snowball stemmer')\n",
    "print(snowball.stem('hobby'))\n",
    "print(snowball.stem('hobbies'))\n",
    "print(snowball.stem('computer'))\n",
    "print(snowball.stem('computation'))\n",
    "print(snowball.stem('best'))\n",
    "print('<--------------------------------------------------------->')\n",
    "print('Lancaster stemmer')\n",
    "print(lancaster.stem('hobby'))\n",
    "print(lancaster.stem('hobbies'))\n",
    "print(lancaster.stem('computer'))\n",
    "print(lancaster.stem('computation'))\n",
    "print(lancaster.stem('best'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3a0cebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porter  :  i wa go to the offic on my bike when i saw a car pass by hit a tree\n",
      "lancaster  :  i was going to the off on my bik when i saw a car pass by hit a tre\n",
      "snowball  :  i was go to the offic on my bike when i saw a car pass by hit a tree\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I was going to the office on my bike when I saw a car passing by hit a tree'\n",
    "\n",
    "words = nltk.word_tokenize(sentence)\n",
    "\n",
    "methods = [(porter, 'porter'), (lancaster, 'lancaster') , (snowball, 'snowball')]\n",
    "\n",
    "for algo in methods : \n",
    "    result = []\n",
    "    for word in words : \n",
    "        result.append(algo[0].stem(word))\n",
    "    print(algo[1], ' : ', ' '.join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8435c8",
   "metadata": {},
   "source": [
    "<h3>Lemmatization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ee3d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/aman.satyawali/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet') # Library built for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b47d1c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(lemma.lemmatize('running', pos = 'v'))\n",
    "print(lemma.lemmatize('runs', pos = 'v'))\n",
    "print(lemma.lemmatize('ran', pos = 'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ed479",
   "metadata": {},
   "source": [
    "<b>Lemmatizer is very complex and takes very long to calculate\n",
    "\n",
    "so, it should only be used when the meaning and context is important, else stemming should be used\n",
    "\n",
    "Depends on the problem</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e1ed2",
   "metadata": {},
   "source": [
    "<h2>Named Entity Recognition (NER)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adce4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
